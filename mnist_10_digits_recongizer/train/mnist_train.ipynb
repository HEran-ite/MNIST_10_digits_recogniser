{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0037\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 20ms/step - accuracy: 0.9983 - loss: 0.0057\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.9983 - loss: 0.0056\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0035\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 19ms/step - accuracy: 0.9994 - loss: 0.0024\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.1044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=mnist_model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/apple/Desktop/MNIST 10 digits recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Save the trained model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmnist_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39mmnist_model\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/saving/saving_api.py:114\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(filepath)\u001b[39m.\u001b[39mendswith((\u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.hdf5\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m legacy_h5_format\u001b[39m.\u001b[39msave_model_to_hdf5(\n\u001b[1;32m    112\u001b[0m         model, filepath, overwrite, include_optimizer\n\u001b[1;32m    113\u001b[0m     )\n\u001b[0;32m--> 114\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mInvalid filepath extension for saving. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease add either a `.keras` extension for the native Keras \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mformat (recommended) or a `.h5` extension. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUse `model.export(filepath)` if you want to export a SavedModel \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfor use with TFLite/TFServing/etc. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: filepath=\u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=mnist_model."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('mnist_model.h5')\n",
    "model.save('mnist_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute '_get_save_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/apple/Desktop/MNIST 10 digits recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m converter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mTFLiteConverter\u001b[39m.\u001b[39mfrom_keras_model(saved_model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Convert the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tflite_model \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mconvert()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Save the TFLite model to disk\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/MNIST%2010%20digits%20recognizer/mnist_10_digits_recongizer/train/mnist_train.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmnist_model.tflite\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1175\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1174\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1175\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_and_export_metrics(convert_func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1129\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m   1128\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[0;32m-> 1129\u001b[0m result \u001b[39m=\u001b[39m convert_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1130\u001b[0m elapsed_time_ms \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m start_time) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m   1131\u001b[0m \u001b[39mif\u001b[39;00m result:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1641\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m saved_model_convert_result:\n\u001b[1;32m   1638\u001b[0m   \u001b[39mreturn\u001b[39;00m saved_model_convert_result\n\u001b[1;32m   1640\u001b[0m graph_def, input_tensors, output_tensors, frozen_func \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1641\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_freeze_keras_model()\n\u001b[1;32m   1642\u001b[0m )\n\u001b[1;32m   1644\u001b[0m graph_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimize_tf_model(\n\u001b[1;32m   1645\u001b[0m     graph_def, input_tensors, output_tensors, frozen_func\n\u001b[1;32m   1646\u001b[0m )\n\u001b[1;32m   1648\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mconvert(\n\u001b[1;32m   1649\u001b[0m     graph_def, input_tensors, output_tensors\n\u001b[1;32m   1650\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n\u001b[0;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/lite.py:1582\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._freeze_keras_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[39m# If the model's call is not a `tf.function`, then we need to first get its\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \u001b[39m# input signature from `model_input_signature` method. We can't directly\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m \u001b[39m# call `trace_model_call` because otherwise the batch dimension is set\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m \u001b[39m# to None.\u001b[39;00m\n\u001b[1;32m   1577\u001b[0m \u001b[39m# Once we have better support for dynamic shapes, we can remove this.\u001b[39;00m\n\u001b[1;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keras_model\u001b[39m.\u001b[39mcall, _def_function\u001b[39m.\u001b[39mFunction):\n\u001b[1;32m   1579\u001b[0m   \u001b[39m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[39;00m\n\u001b[1;32m   1580\u001b[0m   \u001b[39m# signature including the batch dimension specified by the user.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m   \u001b[39m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[0;32m-> 1582\u001b[0m   input_signature \u001b[39m=\u001b[39m _model_input_signature(\n\u001b[1;32m   1583\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_model, keep_original_batch_size\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   1584\u001b[0m   )\n\u001b[1;32m   1586\u001b[0m \u001b[39m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[1;32m   1587\u001b[0m func \u001b[39m=\u001b[39m _trace_model_call(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keras_model, input_signature)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/lite/python/tflite_keras_util.py:84\u001b[0m, in \u001b[0;36mmodel_input_signature\u001b[0;34m(model, keep_original_batch_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m   input_specs \u001b[39m=\u001b[39m input_specs[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m     83\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m   input_specs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49m_get_save_spec(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     85\u001b[0m       dynamic_batch\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m keep_original_batch_size)\n\u001b[1;32m     86\u001b[0m   \u001b[39mif\u001b[39;00m input_specs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_get_save_spec'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the Keras model from HDF5\n",
    "saved_model = load_model('mnist_model.h5')\n",
    "\n",
    "# Create TFLite converter\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('mnist_model')\n",
    "\n",
    "# Convert the model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to disk\n",
    "with open('mnist_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Load the saved model\n",
    "# saved_model = tf.keras.models.load_model('mnist_model.keras')\n",
    "\n",
    "# # Convert the model to TensorFlow Lite format\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(saved_model)\n",
    "\n",
    "# # Convert the model\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the converted model as .tflite\n",
    "# with open('mnist_model.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
